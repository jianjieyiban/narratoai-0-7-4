# çºªå½•ç‰‡è„šæœ¬ç”Ÿæˆ
import os
import json
import time
import asyncio
import traceback
import streamlit as st
from loguru import logger
from datetime import datetime

from app.config import config
from app.utils import utils, video_processor
from webui.tools.base import create_vision_analyzer, get_batch_files, get_batch_timestamps, chekc_video_config


def generate_script_docu(params):
    """
    ç”Ÿæˆ çºªå½•ç‰‡ è§†é¢‘è„šæœ¬
    è¦æ±‚: åŸè§†é¢‘æ— å­—å¹•æ— é…éŸ³
    é€‚åˆåœºæ™¯: çºªå½•ç‰‡ã€åŠ¨ç‰©æç¬‘è§£è¯´ã€è’é‡å»ºé€ ç­‰
    """
    progress_bar = st.progress(0)
    status_text = st.empty()

    def update_progress(progress: float, message: str = ""):
        progress_bar.progress(progress)
        if message:
            status_text.text(f"ğŸ¬ {message}")
        else:
            status_text.text(f"ğŸ“Š è¿›åº¦: {progress}%")

    try:
        with st.spinner("æ­£åœ¨ç”Ÿæˆè„šæœ¬..."):
            if not params.video_origin_path:
                st.error("è¯·å…ˆé€‰æ‹©è§†é¢‘æ–‡ä»¶")
                return
            """
            1. æå–é”®å¸§
            """
            update_progress(10, "æ­£åœ¨æå–å…³é”®å¸§...")

            # åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºå­˜å‚¨å…³é”®å¸§
            keyframes_dir = os.path.join(utils.temp_dir(), "keyframes")
            
            # å…³é”®ä¿®å¤ï¼šä½¿ç”¨è§†é¢‘æ–‡ä»¶çš„å®Œæ•´è·¯å¾„å’Œä¿®æ”¹æ—¶é—´ç”Ÿæˆå”¯ä¸€å“ˆå¸Œ
            # ç¡®ä¿å³ä½¿æ–‡ä»¶åç›¸åŒï¼Œä½†æ–‡ä»¶å†…å®¹ä¸åŒæ—¶ä¹Ÿèƒ½æ­£ç¡®è¯†åˆ«
            video_path_normalized = os.path.abspath(params.video_origin_path)
            video_mtime = os.path.getmtime(video_path_normalized) if os.path.exists(video_path_normalized) else 0
            video_hash = utils.md5(video_path_normalized + str(video_mtime))
            video_keyframes_dir = os.path.join(keyframes_dir, video_hash)
            
            logger.info(f"è§†é¢‘æ–‡ä»¶: {video_path_normalized}, ä¿®æ”¹æ—¶é—´: {video_mtime}, å“ˆå¸Œ: {video_hash}")

            # æ£€æŸ¥æ˜¯å¦å·²ç»æå–è¿‡å…³é”®å¸§ï¼ˆå¿…é¡»å®Œå…¨åŒ¹é…å½“å‰è§†é¢‘æ–‡ä»¶ï¼‰
            keyframe_files = []
            if os.path.exists(video_keyframes_dir):
                # éªŒè¯ç¼“å­˜ç›®å½•æ˜¯å¦å±äºå½“å‰è§†é¢‘æ–‡ä»¶
                # åŒé‡éªŒè¯ï¼šæ£€æŸ¥ç›®å½•ä¸­çš„æ ‡è®°æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                cache_valid = True
                cache_marker_file = os.path.join(video_keyframes_dir, ".video_info.txt")
                if os.path.exists(cache_marker_file):
                    try:
                        with open(cache_marker_file, 'r', encoding='utf-8') as f:
                            cached_info = f.read().strip()
                            if cached_info != video_path_normalized:
                                logger.warning(f"ç¼“å­˜ç›®å½•çš„è§†é¢‘è·¯å¾„ä¸åŒ¹é…: {cached_info} != {video_path_normalized}")
                                cache_valid = False
                    except Exception as e:
                        logger.warning(f"è¯»å–ç¼“å­˜æ ‡è®°æ–‡ä»¶å¤±è´¥: {e}")
                        cache_valid = False
                
                if cache_valid:
                    # å–å·²æœ‰çš„å…³é”®å¸§æ–‡ä»¶
                    for filename in sorted(os.listdir(video_keyframes_dir)):
                        if filename.endswith('.jpg'):
                            keyframe_files.append(os.path.join(video_keyframes_dir, filename))

                    if keyframe_files:
                        logger.info(f"ä½¿ç”¨å·²ç¼“å­˜çš„å…³é”®å¸§: {video_keyframes_dir}")
                        st.info(f"âœ… ä½¿ç”¨å·²ç¼“å­˜å…³é”®å¸§ï¼Œå…± {len(keyframe_files)} å¸§")
                        update_progress(20, f"ä½¿ç”¨å·²ç¼“å­˜å…³é”®å¸§ï¼Œå…± {len(keyframe_files)} å¸§")
                else:
                    # ç¼“å­˜æ— æ•ˆï¼Œåˆ é™¤æ—§ç¼“å­˜ç›®å½•
                    logger.warning(f"æ£€æµ‹åˆ°æ— æ•ˆç¼“å­˜ï¼Œåˆ é™¤æ—§ç¼“å­˜ç›®å½•: {video_keyframes_dir}")
                    import shutil
                    try:
                        shutil.rmtree(video_keyframes_dir)
                        logger.info("å·²åˆ é™¤æ— æ•ˆç¼“å­˜ç›®å½•")
                    except Exception as e:
                        logger.error(f"åˆ é™¤æ— æ•ˆç¼“å­˜ç›®å½•å¤±è´¥: {e}")

            # å¦‚æœæ²¡æœ‰ç¼“å­˜çš„å…³é”®å¸§ï¼Œåˆ™è¿›è¡Œæå–
            if not keyframe_files:
                try:
                    # ç¡®ä¿ç›®å½•å­˜åœ¨
                    os.makedirs(video_keyframes_dir, exist_ok=True)
                    
                    # å…³é”®ä¿®å¤ï¼šä¿å­˜è§†é¢‘æ–‡ä»¶ä¿¡æ¯åˆ°ç¼“å­˜ç›®å½•ï¼Œç”¨äºåç»­éªŒè¯
                    cache_marker_file = os.path.join(video_keyframes_dir, ".video_info.txt")
                    try:
                        with open(cache_marker_file, 'w', encoding='utf-8') as f:
                            f.write(video_path_normalized)
                        logger.info(f"å·²ä¿å­˜è§†é¢‘ä¿¡æ¯åˆ°ç¼“å­˜æ ‡è®°æ–‡ä»¶: {cache_marker_file}")
                    except Exception as marker_error:
                        logger.warning(f"ä¿å­˜ç¼“å­˜æ ‡è®°æ–‡ä»¶å¤±è´¥: {marker_error}")

                    # åˆå§‹åŒ–è§†é¢‘å¤„ç†å™¨
                    processor = video_processor.VideoProcessor(params.video_origin_path)

                    # éªŒè¯è§†é¢‘ä¿¡æ¯æ˜¯å¦æœ‰æ•ˆ
                    if processor.fps is None or processor.fps <= 0:
                        raise ValueError(f"æ— æ³•è·å–æœ‰æ•ˆçš„è§†é¢‘å¸§ç‡ä¿¡æ¯ï¼Œè¯·æ£€æŸ¥è§†é¢‘æ–‡ä»¶: {params.video_origin_path}")
                    if processor.duration is None or processor.duration <= 0:
                        raise ValueError(f"æ— æ³•è·å–æœ‰æ•ˆçš„è§†é¢‘æ—¶é•¿ä¿¡æ¯ï¼Œè¯·æ£€æŸ¥è§†é¢‘æ–‡ä»¶: {params.video_origin_path}")

                    # æ˜¾ç¤ºè§†é¢‘ä¿¡æ¯
                    st.info(f"ğŸ“¹ è§†é¢‘ä¿¡æ¯: {processor.width}x{processor.height}, {processor.fps:.1f}fps, {processor.duration:.1f}ç§’")

                    # å¤„ç†è§†é¢‘å¹¶æå–å…³é”®å¸§ - ç›´æ¥ä½¿ç”¨è¶…çº§å…¼å®¹æ€§æ–¹æ¡ˆ
                    update_progress(15, "æ­£åœ¨æå–å…³é”®å¸§ï¼ˆä½¿ç”¨è¶…çº§å…¼å®¹æ€§æ–¹æ¡ˆï¼‰...")

                    # è·å–å¸§é—´éš”ï¼Œç¡®ä¿ä¸æ˜¯ None
                    frame_interval = st.session_state.get('frame_interval_input')
                    if frame_interval is None:
                        frame_interval = 5.0  # é»˜è®¤å€¼
                        logger.warning(f"å¸§é—´éš”æœªè®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼: {frame_interval}ç§’")
                    
                    # ç¡®ä¿ frame_interval æ˜¯æœ‰æ•ˆçš„æ•°å­—
                    try:
                        frame_interval = float(frame_interval)
                        if frame_interval <= 0:
                            frame_interval = 5.0
                            logger.warning(f"å¸§é—´éš”æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤å€¼: {frame_interval}ç§’")
                    except (ValueError, TypeError):
                        frame_interval = 5.0
                        logger.warning(f"å¸§é—´éš”æ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤å€¼: {frame_interval}ç§’")

                    try:
                        # ä½¿ç”¨ä¼˜åŒ–çš„å…³é”®å¸§æå–æ–¹æ³•
                        processor.extract_frames_by_interval_ultra_compatible(
                            output_dir=video_keyframes_dir,
                            interval_seconds=frame_interval,
                        )
                    except Exception as extract_error:
                        logger.error(f"å…³é”®å¸§æå–å¤±è´¥: {extract_error}")
                        
                        # æä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œè§£å†³å»ºè®®
                        error_msg = str(extract_error)
                        if "æƒé™" in error_msg or "permission" in error_msg.lower():
                            suggestion = "å»ºè®®ï¼šæ£€æŸ¥è¾“å‡ºç›®å½•æƒé™ï¼Œæˆ–æ›´æ¢è¾“å‡ºä½ç½®"
                        elif "ç©ºé—´" in error_msg or "space" in error_msg.lower():
                            suggestion = "å»ºè®®ï¼šæ£€æŸ¥ç£ç›˜ç©ºé—´æ˜¯å¦è¶³å¤Ÿ"
                        else:
                            suggestion = "å»ºè®®ï¼šæ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦æŸåï¼Œæˆ–å°è¯•è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼"

                        raise Exception(f"å…³é”®å¸§æå–å¤±è´¥: {error_msg}\n{suggestion}")

                    # è·å–æ‰€æœ‰å…³é”®æ–‡ä»¶è·¯å¾„
                    for filename in sorted(os.listdir(video_keyframes_dir)):
                        if filename.endswith('.jpg'):
                            keyframe_files.append(os.path.join(video_keyframes_dir, filename))

                    if not keyframe_files:
                        # æ£€æŸ¥ç›®å½•ä¸­æ˜¯å¦æœ‰å…¶ä»–æ–‡ä»¶
                        all_files = os.listdir(video_keyframes_dir)
                        logger.error(f"å…³é”®å¸§ç›®å½•å†…å®¹: {all_files}")
                        raise Exception("æœªæå–åˆ°ä»»ä½•å…³é”®å¸§æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ ¼å¼")

                    update_progress(20, f"å…³é”®å¸§æå–å®Œæˆï¼Œå…± {len(keyframe_files)} å¸§")
                    st.success(f"âœ… æˆåŠŸæå– {len(keyframe_files)} ä¸ªå…³é”®å¸§")

                except Exception as e:
                    # å¦‚æœæå–å¤±è´¥ï¼Œæ¸…ç†åˆ›å»ºçš„ç›®å½•
                    try:
                        if os.path.exists(video_keyframes_dir):
                            import shutil
                            shutil.rmtree(video_keyframes_dir)
                    except Exception as cleanup_err:
                        logger.error(f"æ¸…ç†å¤±è´¥çš„å…³é”®å¸§ç›®å½•æ—¶å‡ºé”™: {cleanup_err}")

                    raise Exception(f"å…³é”®å¸§æå–å¤±è´¥: {str(e)}")

            """
            2. è§†è§‰åˆ†æ(æ‰¹é‡åˆ†ææ¯ä¸€å¸§)
            """
            # ç¡®ä¿LLMæä¾›å•†å·²æ³¨å†Œï¼ˆé˜²æ­¢Streamlité‡è½½æ—¶æä¾›å•†æœªæ³¨å†Œï¼‰
            try:
                from app.services.llm.manager import LLMServiceManager
                if not LLMServiceManager.is_registered():
                    logger.warning("LLMæä¾›å•†æœªæ³¨å†Œï¼Œå°è¯•é‡æ–°æ³¨å†Œ...")
                    from app.services.llm.providers import register_all_providers
                    register_all_providers()
                    logger.info("LLMæä¾›å•†é‡æ–°æ³¨å†ŒæˆåŠŸ")
            except Exception as reg_error:
                logger.warning(f"LLMæä¾›å•†æ³¨å†Œæ£€æŸ¥å¤±è´¥: {reg_error}ï¼Œç»§ç»­å°è¯•åˆ›å»ºåˆ†æå™¨")
            
            # æœ€ä½³å®è·µï¼šä½¿ç”¨ get() çš„é»˜è®¤å€¼å‚æ•° + ä» config è·å–å¤‡ç”¨å€¼
            vision_llm_provider = (
                st.session_state.get('vision_llm_provider') or
                config.app.get('vision_llm_provider', 'litellm')
            ).lower()

            logger.info(f"ä½¿ç”¨ {vision_llm_provider.upper()} è¿›è¡Œè§†è§‰åˆ†æ")

            try:
                # ===================åˆå§‹åŒ–è§†è§‰åˆ†æå™¨===================
                update_progress(30, "æ­£åœ¨åˆå§‹åŒ–è§†è§‰åˆ†æå™¨...")

                # ä½¿ç”¨ç»Ÿä¸€çš„é…ç½®é”®æ ¼å¼è·å–é…ç½®ï¼ˆæ”¯æŒæ‰€æœ‰ providerï¼‰
                vision_api_key = (
                    st.session_state.get(f'vision_{vision_llm_provider}_api_key') or
                    config.app.get(f'vision_{vision_llm_provider}_api_key')
                )
                vision_model = (
                    st.session_state.get(f'vision_{vision_llm_provider}_model_name') or
                    config.app.get(f'vision_{vision_llm_provider}_model_name')
                )
                vision_base_url = (
                    st.session_state.get(f'vision_{vision_llm_provider}_base_url') or
                    config.app.get(f'vision_{vision_llm_provider}_base_url', '')
                )

                # éªŒè¯å¿…éœ€é…ç½®
                if not vision_api_key or not vision_model:
                    raise ValueError(
                        f"æœªé…ç½® {vision_llm_provider} çš„ API Key æˆ–æ¨¡å‹åç§°ã€‚"
                        f"è¯·åœ¨è®¾ç½®é¡µé¢é…ç½® vision_{vision_llm_provider}_api_key å’Œ vision_{vision_llm_provider}_model_name"
                    )

                # åˆ›å»ºè§†è§‰åˆ†æå™¨å®ä¾‹ï¼ˆä½¿ç”¨ç»Ÿä¸€æ¥å£ï¼‰
                llm_params = {
                    "vision_provider": vision_llm_provider,
                    "vision_api_key": vision_api_key,
                    "vision_model_name": vision_model,
                    "vision_base_url": vision_base_url,
                }

                logger.debug(f"è§†è§‰åˆ†æå™¨é…ç½®: provider={vision_llm_provider}, model={vision_model}")

                analyzer = create_vision_analyzer(
                    provider=vision_llm_provider,
                    api_key=vision_api_key,
                    model=vision_model,
                    base_url=vision_base_url
                )

                # è®¡ç®—æ‰¹å¤„ç†å‚æ•°
                vision_batch_size = st.session_state.get('vision_batch_size') or config.frames.get("vision_batch_size")
                total_frames = len(keyframe_files)
                estimated_batches = (total_frames + vision_batch_size - 1) // vision_batch_size
                
                # å¯¹äºå°‘é‡å¸§ï¼Œå¯ä»¥å‡å°‘æ‰¹å¤„ç†å¤§å°ä»¥æé«˜æ•ˆç‡
                if total_frames <= 10 and vision_batch_size > 10:
                    vision_batch_size = min(10, total_frames)
                    logger.info(f"å¸§æ•°è¾ƒå°‘({total_frames}å¸§)ï¼Œè°ƒæ•´æ‰¹å¤„ç†å¤§å°ä¸º{vision_batch_size}")
                
                logger.info(f"å¼€å§‹è§†è§‰åˆ†æ: å…±{total_frames}å¸§ï¼Œæ‰¹å¤„ç†å¤§å°={vision_batch_size}ï¼Œé¢„è®¡{estimated_batches}ä¸ªæ‰¹æ¬¡")
                update_progress(40, f"æ­£åœ¨åˆ†æå…³é”®å¸§ ({total_frames}å¸§ï¼Œé¢„è®¡{estimated_batches}ä¸ªæ‰¹æ¬¡)...")

                # ===================åˆ›å»ºå¼‚æ­¥äº‹ä»¶å¾ªç¯===================
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)

                vision_analysis_prompt = """
æˆ‘æä¾›äº† %s å¼ è§†é¢‘å¸§ï¼Œå®ƒä»¬æŒ‰æ—¶é—´é¡ºåºæ’åˆ—ï¼Œä»£è¡¨ä¸€ä¸ªè¿ç»­çš„è§†é¢‘ç‰‡æ®µã€‚è¯·ä»”ç»†åˆ†ææ¯ä¸€å¸§çš„å†…å®¹ï¼Œå¹¶å…³æ³¨å¸§ä¸å¸§ä¹‹é—´çš„å˜åŒ–ï¼Œä»¥ç†è§£æ•´ä¸ªç‰‡æ®µçš„æ´»åŠ¨ã€‚

**å…³é”®è¦æ±‚ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰**ï¼š
1. **çœŸå®å®¢è§‚**ï¼šåªèƒ½æè¿°ç”»é¢é‡Œçœ‹å¾—è§çš„å†…å®¹ï¼Œä¸¥ç¦çŒœæµ‹æˆ–æ²¿ç”¨æ¨¡æ¿ç»éªŒã€‚
2. **åŠ¨ç‰©è¯†åˆ«**ï¼š
   - è¯·ç»“åˆä½“å‹ã€æ¯›è‰²ã€èŠ±çº¹ã€è€³æœµå½¢çŠ¶ã€å°¾å·´å½¢çŠ¶ã€æ˜¯å¦æœ‰èƒ¡é¡»/æ¡çº¹/çˆªå­ç­‰ç‰¹å¾æ¥åˆ¤æ–­å…·ä½“åŠ¨ç‰©ç§ç±»ã€‚
   - ä¾‹å¦‚ï¼šæ¾é¼ /èŠ±æ —é¼ ï¼ˆæ¡çº¹èƒŒã€è“¬æ¾å¤§å°¾å·´ã€å•ƒåšæœï¼‰ã€å…”å­ï¼ˆé•¿è€³ã€çŸ­å°¾ï¼‰ã€å°çŒªï¼ˆæ— æ¡çº¹ã€æ‰å¹³çŒªé¼»å­ã€çš®è‚¤ç²‰è‰²æˆ–ç°è‰²ï¼‰ã€ç‹—/çŒ«ï¼ˆæ˜æ˜¾çš„å»éƒ¨ã€çˆªå­ï¼‰ã€‚
   - **è‹¥æ— æ³•ç™¾åˆ†ç™¾ç¡®è®¤ç‰©ç§ï¼ŒåŠ¡å¿…æè¿°å¤–è²Œç‰¹å¾ï¼Œä¸è¦éšæ„å†™â€œå°çŒªâ€â€œå°ç‹—â€ç­‰å†œåœºåŠ¨ç‰©ã€‚**
3. **è¡Œä¸ºä¸ç¯å¢ƒ**ï¼š
   - å…·ä½“æè¿°åŠ¨ç‰©æˆ–äººç‰©æ­£åœ¨åšçš„åŠ¨ä½œï¼ˆå¦‚â€œæŠ±ç€åšæœå•ƒé£Ÿâ€â€œä½å¤´èˆ”æ°´â€â€œæŠ¬å¤´å¼ æœ›â€ï¼‰ã€‚
   - å‡†ç¡®æè¿°åœºæ™¯ï¼šæ£®æ—ã€æ ‘æ¡©ã€æˆ·å¤–æœ¨æ¡Œã€å®¤å†…å®¢å…ã€å†œåœºçŒªåœˆç­‰ã€‚è‹¥åœºæ™¯ä¸åƒå…»æ®–åœºï¼Œå°±ä¸è¦å†™â€œçŒªåœˆã€é£Ÿæ§½â€ã€‚
4. **ä¸¥ç¦è¯¯åˆ¤**ï¼š
   - çœ‹åˆ°æ¡çº¹èƒŒçš„å°å‹å•®é½¿åŠ¨ç‰©æ—¶ï¼Œä¸èƒ½å†™æˆâ€œå°çŒªâ€ã€‚
   - å¦‚æœç”»é¢æ˜¾ç¤ºè‡ªç„¶æ£®æ—æˆ–æœ¨æ¡©ï¼Œè¯·å†™æˆâ€œæ£®æ—/æ—åœ°/æˆ·å¤–â€ï¼Œä¸è¦å†™æˆâ€œæ°´æ³¥åœ°é¢ã€å…»æ®–åœºâ€ã€‚
   - å¦‚æœ‰ç–‘é—®ï¼Œå¯è¯´æ˜â€œä¸ç¡®å®šçš„ç‰©ç§ï¼Œå…·å¤‡Ã—Ã—ç‰¹å¾â€ã€‚æ¯”éšæ„çŒœæˆå†œåœºåŠ¨ç‰©æ›´å¥½ã€‚

é¦–å…ˆï¼Œè¯·è¯¦ç»†æè¿°æ¯ä¸€å¸§çš„å…³é”®è§†è§‰ä¿¡æ¯ï¼ˆå¿…é¡»åŸºäºå®é™…ç”»é¢ï¼Œä¸¥ç¦è™šæ„ï¼‰ï¼š
- **å‡†ç¡®è¯†åˆ«å†…å®¹**ï¼šäººç‰©ã€åŠ¨ç‰©ã€ç‰©ä½“ã€åœºæ™¯ç±»å‹
- **å‡†ç¡®æè¿°è¡Œä¸º**ï¼šå®é™…å‘ç”Ÿçš„åŠ¨ä½œå’Œè¡Œä¸º
- **å‡†ç¡®æè¿°ç¯å¢ƒ**ï¼šå®é™…åœ°ç‚¹å’Œåœºæ™¯

ç„¶åï¼ŒåŸºäºæ‰€æœ‰å¸§çš„åˆ†æï¼Œè¯·ç”¨**ç®€æ´çš„è¯­è¨€**æ€»ç»“æ•´ä¸ªè§†é¢‘ç‰‡æ®µä¸­å‘ç”Ÿçš„ä¸»è¦æ´»åŠ¨æˆ–äº‹ä»¶æµç¨‹ï¼ˆå¿…é¡»åŸºäºå®é™…ç”»é¢å†…å®¹ï¼Œä¸èƒ½è™šæ„ï¼‰ã€‚

è¯·åŠ¡å¿…ä½¿ç”¨ JSON æ ¼å¼è¾“å‡ºä½ çš„ç»“æœã€‚JSON ç»“æ„åº”å¦‚ä¸‹ï¼š
{
  "frame_observations": [
    {
      "frame_number": 1,
      "observation": "å‡†ç¡®æè¿°æ¯å¼ è§†é¢‘å¸§ä¸­çš„å®é™…å†…å®¹ï¼šä¸»è¦å†…å®¹ã€äººç‰©/åŠ¨ç‰©ã€åŠ¨ä½œå’Œåœºæ™¯ã€‚å¿…é¡»åŸºäºå®é™…ç”»é¢ï¼Œä¸èƒ½è™šæ„ã€‚"
    },
    // ... æ›´å¤šå¸§çš„è§‚å¯Ÿ ...
  ],
  "overall_activity_summary": "åŸºäºå®é™…ç”»é¢æ€»ç»“çš„ä¸»è¦æ´»åŠ¨ï¼Œä¿æŒç®€æ´ï¼Œä¸èƒ½è™šæ„ã€‚"
}

è¯·åŠ¡å¿…ä¸è¦é—æ¼è§†é¢‘å¸§ï¼Œæˆ‘æä¾›äº† %s å¼ è§†é¢‘å¸§ï¼Œframe_observations å¿…é¡»åŒ…å« %s ä¸ªå…ƒç´ 

è¯·åªè¿”å› JSON å­—ç¬¦ä¸²ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–è§£é‡Šæ€§æ–‡å­—ã€‚
                """
                # æ ¼å¼åŒ–æç¤ºè¯ï¼Œå¡«å……å¸§æ•°é‡
                formatted_prompt = vision_analysis_prompt % (len(keyframe_files), len(keyframe_files), len(keyframe_files))
                
                # æ·»åŠ å¸¦è¿›åº¦çš„æ‰¹å¤„ç†åŒ…è£…
                async def analyze_with_progress():
                    """å¸¦è¿›åº¦æ˜¾ç¤ºçš„æ‰¹å¤„ç†åˆ†æ"""
                    all_results = []
                    batch_count = (len(keyframe_files) + vision_batch_size - 1) // vision_batch_size
                    
                    for batch_idx in range(0, len(keyframe_files), vision_batch_size):
                        batch_files = keyframe_files[batch_idx:batch_idx + vision_batch_size]
                        current_batch = batch_idx // vision_batch_size + 1
                        
                        # æ›´æ–°è¿›åº¦
                        progress_pct = 40 + int((current_batch / batch_count) * 20)  # 40-60%
                        update_progress(progress_pct, f"æ­£åœ¨åˆ†æç¬¬{current_batch}/{batch_count}æ‰¹æ¬¡ ({len(batch_files)}å¸§)...")
                        logger.info(f"å¤„ç†æ‰¹æ¬¡ {current_batch}/{batch_count}: {len(batch_files)}å¼ å›¾ç‰‡")
                        
                        try:
                            batch_result = None
                            max_retries = 2
                            for attempt in range(max_retries):
                                try:
                                    # ä½¿ç”¨asyncio.wait_foræ·»åŠ è¶…æ—¶æ§åˆ¶
                                    batch_result = await asyncio.wait_for(
                                        analyzer.analyze_images(
                                            images=batch_files,
                                            prompt=formatted_prompt,
                                            batch_size=len(batch_files),  # è¿™ä¸ªæ‰¹æ¬¡çš„å®é™…å¤§å°
                                            timeout=600,
                                            retries=2
                                        ),
                                        timeout=600  # 10åˆ†é’Ÿè¶…æ—¶
                                    )
                                    break
                                except asyncio.TimeoutError:
                                    logger.warning(f"æ‰¹æ¬¡{current_batch}åœ¨ç¬¬{attempt + 1}æ¬¡å°è¯•æ—¶è¶…æ—¶ï¼Œæ­£åœ¨é‡è¯•...")
                                    if attempt < max_retries - 1:
                                        await asyncio.sleep(2)
                                        continue
                                    raise
                            if batch_result is None:
                                raise asyncio.TimeoutError()
                            
                            # analyzer.analyze_imagesè¿”å›List[Dict]ï¼Œå¯¹äºå•ä¸ªæ‰¹æ¬¡é€šå¸¸åªæœ‰ä¸€ä¸ªå…ƒç´ 
                            # å¤„ç†è¿”å›ç»“æœ
                            if isinstance(batch_result, list) and len(batch_result) > 0:
                                # å–ç¬¬ä¸€ä¸ªç»“æœï¼ˆå•ä¸ªæ‰¹æ¬¡åº”è¯¥åªæœ‰ä¸€ä¸ªç»“æœï¼‰
                                batch_result_dict = batch_result[0] if isinstance(batch_result[0], dict) else {
                                    'batch_index': current_batch - 1,
                                    'response': str(batch_result[0]) if batch_result[0] else '',
                                    'images_processed': len(batch_files)
                                }
                                batch_result_dict['batch_index'] = current_batch - 1
                                all_results.append(batch_result_dict)
                            elif isinstance(batch_result, dict):
                                batch_result['batch_index'] = current_batch - 1
                                all_results.append(batch_result)
                            else:
                                logger.warning(f"æ‰¹æ¬¡{current_batch}è¿”å›æ ¼å¼å¼‚å¸¸: {type(batch_result)}")
                                # å°è¯•è½¬æ¢
                                all_results.append({
                                    'batch_index': current_batch - 1,
                                    'response': str(batch_result) if batch_result else '',
                                    'images_processed': len(batch_files)
                                })
                                
                        except asyncio.TimeoutError:
                            logger.error(f"æ‰¹æ¬¡{current_batch}å¤„ç†è¶…æ—¶ï¼ˆè¶…è¿‡5åˆ†é’Ÿï¼‰")
                            all_results.append({
                                'batch_index': current_batch - 1,
                                'error': f'å¤„ç†è¶…æ—¶ï¼ˆè¶…è¿‡5åˆ†é’Ÿï¼‰ï¼Œå¯èƒ½APIå“åº”è¿‡æ…¢',
                                'images_processed': len(batch_files)
                            })
                        except Exception as e:
                            logger.error(f"æ‰¹æ¬¡{current_batch}å¤„ç†å¤±è´¥: {str(e)}")
                            all_results.append({
                                'batch_index': current_batch - 1,
                                'error': str(e),
                                'images_processed': len(batch_files)
                            })
                        
                        # æ‰¹æ¬¡é—´çŸ­æš‚åœé¡¿ï¼Œé¿å…APIé™æµ
                        if current_batch < batch_count:
                            await asyncio.sleep(0.5)
                    
                    return all_results
                
                try:
                    results = loop.run_until_complete(analyze_with_progress())
                except Exception as e:
                    logger.exception(f"è§†è§‰åˆ†æAPIè°ƒç”¨å¤±è´¥: {str(e)}")
                    raise Exception(f"è§†è§‰åˆ†æAPIè°ƒç”¨å¤±è´¥: {str(e)}\n\nè¯·æ£€æŸ¥ï¼š\n1. APIé…ç½®æ˜¯å¦æ­£ç¡®\n2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n3. APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ\n4. å¦‚æœé•¿æ—¶é—´æ— å“åº”ï¼Œå¯èƒ½æ˜¯APIæœåŠ¡å¼‚å¸¸")
                finally:
                    loop.close()
                
                # éªŒè¯resultsä¸ä¸ºç©º
                if not results:
                    raise Exception("è§†è§‰åˆ†ææœªè¿”å›ä»»ä½•ç»“æœï¼Œå¯èƒ½APIè°ƒç”¨å¤±è´¥")
                
                # ç»Ÿè®¡æˆåŠŸå’Œå¤±è´¥çš„æ‰¹æ¬¡
                success_count = sum(1 for r in results if 'error' not in r)
                error_count = sum(1 for r in results if 'error' in r)
                
                logger.info(f"è§†è§‰åˆ†æå®Œæˆ: å…±{len(results)}ä¸ªæ‰¹æ¬¡ï¼ŒæˆåŠŸ{success_count}ä¸ªï¼Œå¤±è´¥{error_count}ä¸ª")
                update_progress(60, f"è§†è§‰åˆ†æå®Œæˆ ({success_count}/{len(results)}æ‰¹æ¬¡æˆåŠŸ)")
                
                if error_count > 0 and success_count == 0:
                    # æ‰€æœ‰æ‰¹æ¬¡éƒ½å¤±è´¥äº†
                    error_messages = [r.get('error', 'æœªçŸ¥é”™è¯¯') for r in results if 'error' in r]
                    raise Exception(f"æ‰€æœ‰æ‰¹æ¬¡å¤„ç†å¤±è´¥ã€‚é”™è¯¯ä¿¡æ¯: {error_messages[0] if error_messages else 'æœªçŸ¥é”™è¯¯'}")

                """
                3. å¤„ç†åˆ†æç»“æœï¼ˆæ ¼å¼åŒ–ä¸º json æ•°æ®ï¼‰
                """
                # ===================å¤„ç†åˆ†æç»“æœ===================
                update_progress(60, "æ­£åœ¨æ•´ç†åˆ†æç»“æœ...")

                # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡çš„åˆ†æç»“æœ
                frame_analysis = ""
                merged_frame_observations = []  # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡çš„å¸§è§‚å¯Ÿ
                overall_activity_summaries = []  # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡çš„æ•´ä½“æ€»ç»“
                prev_batch_files = None
                frame_counter = 1  # åˆå§‹åŒ–å¸§è®¡æ•°å™¨ï¼Œç”¨äºç»™æ‰€æœ‰å¸§åˆ†é…è¿ç»­çš„åºå·
                
                # ç¡®ä¿åˆ†æç›®å½•å­˜åœ¨
                analysis_dir = os.path.join(utils.storage_dir(), "temp", "analysis")
                os.makedirs(analysis_dir, exist_ok=True)
                origin_res = os.path.join(analysis_dir, "frame_analysis.json")
                with open(origin_res, 'w', encoding='utf-8') as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)
                
                # å¼€å§‹å¤„ç†
                for result in results:
                    if 'error' in result:
                        logger.warning(f"æ‰¹æ¬¡ {result['batch_index']} å¤„ç†å‡ºç°è­¦å‘Š: {result['error']}")
                        continue
                        
                    # è·å–å½“å‰æ‰¹æ¬¡çš„æ–‡ä»¶åˆ—è¡¨
                    batch_files = get_batch_files(keyframe_files, result, vision_batch_size)
                    
                    # è·å–æ‰¹æ¬¡çš„æ—¶é—´æˆ³èŒƒå›´
                    first_timestamp, last_timestamp, timestamp_range = get_batch_timestamps(batch_files, prev_batch_files)
                    
                    # è§£æå“åº”ä¸­çš„JSONæ•°æ®
                    response_text = result['response']
                    try:
                        # å¤„ç†å¯èƒ½åŒ…å«```json```æ ¼å¼çš„å“åº”
                        if "```json" in response_text:
                            json_content = response_text.split("```json")[1].split("```")[0].strip()
                        elif "```" in response_text:
                            json_content = response_text.split("```")[1].split("```")[0].strip()
                        else:
                            json_content = response_text.strip()
                            
                        response_data = json.loads(json_content)
                        
                        # æå–frame_observationså’Œoverall_activity_summary
                        if "frame_observations" in response_data:
                            frame_obs = response_data["frame_observations"]
                            overall_summary = response_data.get("overall_activity_summary", "")
                            
                            # æ·»åŠ æ—¶é—´æˆ³ä¿¡æ¯åˆ°æ¯ä¸ªå¸§è§‚å¯Ÿ
                            for i, obs in enumerate(frame_obs):
                                if i < len(batch_files):
                                    # ä»æ–‡ä»¶åä¸­æå–æ—¶é—´æˆ³
                                    file_path = batch_files[i]
                                    file_name = os.path.basename(file_path)
                                    # æå–æ—¶é—´æˆ³å­—ç¬¦ä¸² (æ ¼å¼å¦‚: keyframe_000675_000027000.jpg)
                                    # æ ¼å¼è§£æ: keyframe_å¸§åºå·_æ¯«ç§’æ—¶é—´æˆ³.jpg
                                    timestamp_parts = file_name.split('_')
                                    if len(timestamp_parts) >= 3:
                                        timestamp_str = timestamp_parts[-1].split('.')[0]
                                        try:
                                            # ä¿®æ­£æ—¶é—´æˆ³è§£æé€»è¾‘
                                            # æ ¼å¼ä¸º000100000ï¼Œè¡¨ç¤º00:01:00,000ï¼Œå³1åˆ†é’Ÿ
                                            # éœ€è¦æŒ‰ç…§å¯¹åº”ä½æ•°è¿›è¡Œè§£æ:
                                            # å‰ä¸¤ä½æ˜¯å°æ—¶ï¼Œä¸­é—´ä¸¤ä½æ˜¯åˆ†é’Ÿï¼Œåé¢æ˜¯ç§’å’Œæ¯«ç§’
                                            if len(timestamp_str) >= 9:  # ç¡®ä¿æ ¼å¼æ­£ç¡®
                                                hours = int(timestamp_str[0:2])
                                                minutes = int(timestamp_str[2:4])
                                                seconds = int(timestamp_str[4:6])
                                                milliseconds = int(timestamp_str[6:9])
                                                
                                                # è®¡ç®—æ€»ç§’æ•°
                                                timestamp_seconds = hours * 3600 + minutes * 60 + seconds + milliseconds / 1000
                                                formatted_time = utils.format_time(timestamp_seconds)  # æ ¼å¼åŒ–æ—¶é—´æˆ³
                                            else:
                                                # å…¼å®¹æ—§çš„è§£ææ–¹å¼
                                                timestamp_seconds = int(timestamp_str) / 1000  # è½¬æ¢ä¸ºç§’
                                                formatted_time = utils.format_time(timestamp_seconds)  # æ ¼å¼åŒ–æ—¶é—´æˆ³
                                        except ValueError:
                                            logger.warning(f"æ— æ³•è§£ææ—¶é—´æˆ³: {timestamp_str}")
                                            timestamp_seconds = 0
                                            formatted_time = "00:00:00,000"
                                    else:
                                        logger.warning(f"æ–‡ä»¶åæ ¼å¼ä¸ç¬¦åˆé¢„æœŸ: {file_name}")
                                        timestamp_seconds = 0
                                        formatted_time = "00:00:00,000"
                                    
                                    # æ·»åŠ é¢å¤–ä¿¡æ¯åˆ°å¸§è§‚å¯Ÿ
                                    obs["frame_path"] = file_path
                                    obs["timestamp"] = formatted_time
                                    obs["timestamp_seconds"] = timestamp_seconds
                                    obs["batch_index"] = result['batch_index']
                                    
                                    # ä½¿ç”¨å…¨å±€é€’å¢çš„å¸§è®¡æ•°å™¨æ›¿æ¢åŸå§‹çš„frame_number
                                    if "frame_number" in obs:
                                        obs["original_frame_number"] = obs["frame_number"]  # ä¿ç•™åŸå§‹ç¼–å·ä½œä¸ºå‚è€ƒ
                                    obs["frame_number"] = frame_counter  # èµ‹å€¼è¿ç»­çš„å¸§ç¼–å·
                                    frame_counter += 1  # å¢åŠ å¸§è®¡æ•°å™¨
                                    
                                    # æ·»åŠ åˆ°åˆå¹¶åˆ—è¡¨
                                    merged_frame_observations.append(obs)
                            
                            # æ·»åŠ æ‰¹æ¬¡æ•´ä½“æ€»ç»“ä¿¡æ¯
                            if overall_summary:
                                # ä»æ–‡ä»¶åä¸­æå–æ—¶é—´æˆ³æ•°å€¼
                                first_time_str = first_timestamp.split('_')[-1].split('.')[0]
                                last_time_str = last_timestamp.split('_')[-1].split('.')[0]
                                
                                # è½¬æ¢ä¸ºæ¯«ç§’å¹¶è®¡ç®—æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
                                try:
                                    # ä¿®æ­£è§£æé€»è¾‘ï¼Œä¸ä¸Šé¢ç›¸åŒçš„æ–¹å¼è§£ææ—¶é—´æˆ³
                                    if len(first_time_str) >= 9 and len(last_time_str) >= 9:
                                        # è§£æç¬¬ä¸€ä¸ªæ—¶é—´æˆ³
                                        first_hours = int(first_time_str[0:2])
                                        first_minutes = int(first_time_str[2:4])
                                        first_seconds = int(first_time_str[4:6])
                                        first_ms = int(first_time_str[6:9])
                                        first_time_seconds = first_hours * 3600 + first_minutes * 60 + first_seconds + first_ms / 1000
                                        
                                        # è§£æç¬¬äºŒä¸ªæ—¶é—´æˆ³
                                        last_hours = int(last_time_str[0:2])
                                        last_minutes = int(last_time_str[2:4])
                                        last_seconds = int(last_time_str[4:6])
                                        last_ms = int(last_time_str[6:9])
                                        last_time_seconds = last_hours * 3600 + last_minutes * 60 + last_seconds + last_ms / 1000
                                        
                                        batch_duration = last_time_seconds - first_time_seconds
                                    else:
                                        # å…¼å®¹æ—§çš„è§£ææ–¹å¼
                                        first_time_ms = int(first_time_str)
                                        last_time_ms = int(last_time_str)
                                        batch_duration = (last_time_ms - first_time_ms) / 1000
                                except ValueError:
                                    # ä½¿ç”¨ utils.time_to_seconds å‡½æ•°å¤„ç†æ ¼å¼åŒ–çš„æ—¶é—´æˆ³
                                    first_time_seconds = utils.time_to_seconds(first_time_str.replace('_', ':').replace('-', ','))
                                    last_time_seconds = utils.time_to_seconds(last_time_str.replace('_', ':').replace('-', ','))
                                    batch_duration = last_time_seconds - first_time_seconds
                                
                                overall_activity_summaries.append({
                                    "batch_index": result['batch_index'],
                                    "time_range": f"{first_timestamp}-{last_timestamp}",
                                    "duration_seconds": batch_duration,
                                    "summary": overall_summary
                                })
                    except Exception as e:
                        logger.error(f"è§£ææ‰¹æ¬¡ {result['batch_index']} çš„å“åº”æ•°æ®å¤±è´¥: {str(e)}")
                        # æ·»åŠ åŸå§‹å“åº”ä½œä¸ºå›é€€
                        frame_analysis += f"\n=== {first_timestamp}-{last_timestamp} ===\n"
                        frame_analysis += response_text
                        frame_analysis += "\n"
                    
                    # æ›´æ–°ä¸Šä¸€ä¸ªæ‰¹æ¬¡çš„æ–‡ä»¶
                    prev_batch_files = batch_files
                
                # éªŒè¯åˆ†æç»“æœæ˜¯å¦æœ‰æ•ˆ
                if not merged_frame_observations and not overall_activity_summaries:
                    logger.error("è§†è§‰åˆ†ææœªè¿”å›æœ‰æ•ˆæ•°æ®")
                    logger.error(f"åˆ†æç»“æœè¯¦æƒ…: resultsæ•°é‡={len(results)}, åŒ…å«é”™è¯¯çš„æ‰¹æ¬¡={sum(1 for r in results if 'error' in r)}")
                    
                    # å°è¯•è¯Šæ–­é—®é¢˜
                    error_details = []
                    for result in results:
                        if 'error' in result:
                            error_details.append(f"æ‰¹æ¬¡{result['batch_index']}: {result['error']}")
                        else:
                            # æ£€æŸ¥å“åº”å†…å®¹
                            response_text = result.get('response', '')
                            if not response_text or not response_text.strip():
                                error_details.append(f"æ‰¹æ¬¡{result['batch_index']}: å“åº”ä¸ºç©º")
                            elif "frame_observations" not in response_text:
                                error_details.append(f"æ‰¹æ¬¡{result['batch_index']}: å“åº”ä¸­ç¼ºå°‘frame_observationså­—æ®µ")
                    
                    error_msg = "âŒ è§†é¢‘å¸§åˆ†æå¤±è´¥ï¼šæœªè·å–åˆ°æœ‰æ•ˆçš„å¸§åˆ†æç»“æœã€‚\n\n"
                    error_msg += "**å¯èƒ½çš„åŸå› ï¼š**\n"
                    error_msg += "1. è§†è§‰åˆ†æAPIè°ƒç”¨å¤±è´¥æˆ–è¿”å›é”™è¯¯\n"
                    error_msg += "2. APIè¿”å›çš„JSONæ ¼å¼ä¸ç¬¦åˆé¢„æœŸ\n"
                    error_msg += "3. ç½‘ç»œè¿æ¥é—®é¢˜å¯¼è‡´è¯·æ±‚è¶…æ—¶\n"
                    error_msg += "4. APIå¯†é’¥æƒé™ä¸è¶³æˆ–å·²è¿‡æœŸ\n\n"
                    
                    if error_details:
                        error_msg += "**è¯¦ç»†é”™è¯¯ä¿¡æ¯ï¼š**\n"
                        for detail in error_details[:5]:  # æœ€å¤šæ˜¾ç¤º5ä¸ªé”™è¯¯
                            error_msg += f"- {detail}\n"
                    
                    error_msg += "\n**å»ºè®®ï¼š**\n"
                    error_msg += "1. æ£€æŸ¥è§†è§‰åˆ†æAPIé…ç½®æ˜¯å¦æ­£ç¡®ï¼ˆå·²æµ‹è¯•è¿æ¥æˆåŠŸä¸ä»£è¡¨å®é™…è°ƒç”¨æˆåŠŸï¼‰\n"
                    error_msg += "2. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶è·å–æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯\n"
                    error_msg += "3. å°è¯•å‡å°‘æ‰¹å¤„ç†å¤§å°ï¼ˆBatch Sizeï¼‰\n"
                    error_msg += "4. æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIé…é¢\n"
                    
                    st.error(error_msg)
                    logger.exception("è§†é¢‘å¸§åˆ†æå®Œæ•´é”™è¯¯ä¿¡æ¯")
                    st.stop()
                    return
                
                # å°†åˆå¹¶åçš„ç»“æœè½¬ä¸ºJSONå­—ç¬¦ä¸²
                merged_results = {
                    "frame_observations": merged_frame_observations,
                    "overall_activity_summaries": overall_activity_summaries
                }
                
                logger.info(f"æˆåŠŸåˆå¹¶åˆ†æç»“æœ: {len(merged_frame_observations)}ä¸ªå¸§è§‚å¯Ÿ, {len(overall_activity_summaries)}ä¸ªæ€»ç»“")
                
                # ä½¿ç”¨å½“å‰æ—¶é—´åˆ›å»ºæ–‡ä»¶å
                now = datetime.now()
                timestamp_str = now.strftime("%Y%m%d_%H%M")
                
                # ä¿å­˜å®Œæ•´çš„åˆ†æç»“æœä¸ºJSONï¼ˆå…³é”®ä¿®å¤ï¼šå…³è”è§†é¢‘æ–‡ä»¶ä¿¡æ¯ï¼‰
                analysis_filename = f"frame_analysis_{timestamp_str}.json"
                analysis_json_path = os.path.join(analysis_dir, analysis_filename)
                
                # å…³é”®ä¿®å¤ï¼šåœ¨åˆ†æç»“æœä¸­æ·»åŠ è§†é¢‘æ–‡ä»¶ä¿¡æ¯ï¼Œç”¨äºåç»­éªŒè¯
                merged_results_with_video_info = {
                    **merged_results,
                    "video_file_path": video_path_normalized,
                    "video_file_hash": video_hash,
                    "analysis_timestamp": timestamp_str
                }
                
                with open(analysis_json_path, 'w', encoding='utf-8') as f:
                    json.dump(merged_results_with_video_info, f, ensure_ascii=False, indent=2)
                logger.info(f"åˆ†æç»“æœå·²ä¿å­˜åˆ°: {analysis_json_path} (å…³è”è§†é¢‘: {video_path_normalized})")

                """
                4. ç”Ÿæˆæ–‡æ¡ˆ
                """
                logger.info("å¼€å§‹ç”Ÿæˆè§£è¯´æ–‡æ¡ˆ")
                update_progress(80, "æ­£åœ¨ç”Ÿæˆè§£è¯´æ–‡æ¡ˆï¼ˆè¿™å¯èƒ½éœ€è¦1-2åˆ†é’Ÿï¼‰...")
                from app.services.generate_narration_script import parse_frame_analysis_to_markdown, generate_narration
                # ä»é…ç½®ä¸­è·å–æ–‡æœ¬ç”Ÿæˆç›¸å…³é…ç½®
                text_provider = config.app.get('text_llm_provider', 'gemini').lower()
                text_api_key = config.app.get(f'text_{text_provider}_api_key')
                text_model = config.app.get(f'text_{text_provider}_model_name')
                text_base_url = config.app.get(f'text_{text_provider}_base_url')
                llm_params.update({
                    "text_provider": text_provider,
                    "text_api_key": text_api_key,
                    "text_model_name": text_model,
                    "text_base_url": text_base_url
                })
                chekc_video_config(llm_params)
                # æ•´ç†å¸§åˆ†ææ•°æ®ï¼ˆå…³é”®ä¿®å¤ï¼šéªŒè¯åˆ†æç»“æœæ˜¯å¦å±äºå½“å‰è§†é¢‘ï¼‰
                markdown_output = parse_frame_analysis_to_markdown(analysis_json_path)
                
                # å…³é”®ä¿®å¤ï¼šéªŒè¯åˆ†æç»“æœæ˜¯å¦å±äºå½“å‰è§†é¢‘æ–‡ä»¶
                try:
                    with open(analysis_json_path, 'r', encoding='utf-8') as f:
                        saved_analysis = json.load(f)
                    saved_video_path = saved_analysis.get('video_file_path', '')
                    saved_video_hash = saved_analysis.get('video_file_hash', '')
                    
                    if saved_video_path and saved_video_path != video_path_normalized:
                        logger.error(f"âŒ ä¸¥é‡é”™è¯¯ï¼šåˆ†æç»“æœæ–‡ä»¶å…³è”çš„è§†é¢‘æ–‡ä»¶ä¸åŒ¹é…ï¼\n"
                                   f"å½“å‰è§†é¢‘: {video_path_normalized}\n"
                                   f"åˆ†æç»“æœå…³è”çš„è§†é¢‘: {saved_video_path}")
                        st.error("âŒ **ä¸¥é‡é”™è¯¯ï¼šæ£€æµ‹åˆ°åˆ†æç»“æœä¸å½“å‰è§†é¢‘ä¸åŒ¹é…ï¼**\n\n"
                                f"**å½“å‰è§†é¢‘æ–‡ä»¶**: `{os.path.basename(video_path_normalized)}`\n"
                                f"**åˆ†æç»“æœå…³è”çš„è§†é¢‘**: `{os.path.basename(saved_video_path)}`\n\n"
                                "è¿™å¯èƒ½å¯¼è‡´ç”»é¢ä¸è§£è¯´ä¸åŒ¹é…ï¼\n\n"
                                "**è§£å†³æ–¹æ¡ˆï¼š**\n"
                                "1. åˆ é™¤æ—§çš„ç¼“å­˜æ–‡ä»¶åé‡æ–°ç”Ÿæˆ\n"
                                "2. ç‚¹å‡»ç³»ç»Ÿè®¾ç½®ä¸­çš„'Clear frames'æ¸…ç†ç¼“å­˜\n"
                                "3. é‡æ–°ç‚¹å‡»'AIç”Ÿæˆç”»é¢è§£è¯´è„šæœ¬'æŒ‰é’®")
                        st.stop()
                        return
                    
                    if saved_video_hash and saved_video_hash != video_hash:
                        logger.error(f"âŒ ä¸¥é‡é”™è¯¯ï¼šåˆ†æç»“æœæ–‡ä»¶çš„è§†é¢‘å“ˆå¸Œä¸åŒ¹é…ï¼\n"
                                   f"å½“å‰è§†é¢‘å“ˆå¸Œ: {video_hash}\n"
                                   f"åˆ†æç»“æœå“ˆå¸Œ: {saved_video_hash}")
                        st.error("âŒ **ä¸¥é‡é”™è¯¯ï¼šæ£€æµ‹åˆ°åˆ†æç»“æœä¸å½“å‰è§†é¢‘ä¸åŒ¹é…ï¼**\n\n"
                                "è§†é¢‘æ–‡ä»¶å¯èƒ½å·²è¢«ä¿®æ”¹æˆ–æ›¿æ¢ã€‚\n\n"
                                "**è§£å†³æ–¹æ¡ˆï¼š**\n"
                                "1. æ¸…ç†ç¼“å­˜åé‡æ–°ç”Ÿæˆ\n"
                                "2. é‡æ–°ç‚¹å‡»'AIç”Ÿæˆç”»é¢è§£è¯´è„šæœ¬'æŒ‰é’®")
                        st.stop()
                        return
                    
                    logger.info(f"âœ… éªŒè¯é€šè¿‡ï¼šåˆ†æç»“æœå±äºå½“å‰è§†é¢‘æ–‡ä»¶")
                except Exception as verify_error:
                    logger.warning(f"éªŒè¯åˆ†æç»“æœå…³è”æ€§æ—¶å‡ºé”™: {verify_error}ï¼Œç»§ç»­æ‰§è¡Œ")
                
                # éªŒè¯markdownè¾“å‡ºæ˜¯å¦æœ‰æ•ˆ
                if not markdown_output or not markdown_output.strip():
                    logger.error("è§†é¢‘å¸§åˆ†æç»“æœä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆè§£è¯´æ–‡æ¡ˆ")
                    st.error("âŒ è§†é¢‘å¸§åˆ†æå¤±è´¥ï¼šæœªè·å–åˆ°æœ‰æ•ˆçš„å¸§åˆ†æç»“æœã€‚è¯·æ£€æŸ¥ï¼š\n"
                            "1. è§†é¢‘æ–‡ä»¶æ˜¯å¦å¯æ­£å¸¸è¯»å–\n"
                            "2. è§†è§‰åˆ†æAPIé…ç½®æ˜¯å¦æ­£ç¡®\n"
                            "3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n"
                            "4. æ˜¯å¦å·²æå–åˆ°å…³é”®å¸§")
                    st.stop()
                    return

                # ç¡®å®šè§†é¢‘ç±»å‹ä»¥é€‰æ‹©æ­£ç¡®çš„æç¤ºè¯
                # ç­–ç•¥ï¼šä¼˜å…ˆæ£€æŸ¥ç”¨æˆ·é€‰æ‹©çš„æ¨¡æ¿ï¼Œç„¶ååŸºäºè§†é¢‘å¸§åˆ†æç»“æœéªŒè¯å’Œè‡ªåŠ¨è¯†åˆ«
                video_type = None
                
                # ç¬¬ä¸€æ­¥ï¼šä¼˜å…ˆæ£€æŸ¥ç”¨æˆ·é€‰æ‹©çš„æ¨¡æ¿ç±»å‹ï¼ˆç”¨æˆ·é€‰æ‹©æ˜¯æœ€é«˜ä¼˜å…ˆçº§ï¼‰
                script_path = st.session_state.get('video_clip_json_path', '')
                logger.info(f"æ£€æŸ¥ç”¨æˆ·é€‰æ‹©çš„æ¨¡æ¿: {script_path}")
                
                if script_path and isinstance(script_path, str):
                    script_path_lower = script_path.lower()
                    if "åŠ¨ç‰©ä¸–ç•Œ" in script_path or "animal" in script_path_lower:
                        # ç”¨æˆ·é€‰æ‹©äº†åŠ¨ç‰©ä¸–ç•Œæ¨¡æ¿ï¼Œä¼˜å…ˆä½¿ç”¨åŠ¨ç‰©ç±»å‹
                        video_type = "animal_world"
                        logger.info(f"âœ… ç”¨æˆ·é€‰æ‹©äº†åŠ¨ç‰©ä¸–ç•Œæ¨¡æ¿ï¼Œä¼˜å…ˆä½¿ç”¨animal_worldç±»å‹")
                    elif "é‡å¤–ç¾é£Ÿ" in script_path or "outdoor" in script_path_lower:
                        video_type = "outdoor_food"
                    elif "å½±è§†è§£è¯´" in script_path or "movie_commentary" in script_path_lower:
                        video_type = "movie_commentary"
                    elif "å½±è§†æ··å‰ª" in script_path or "movie_mashup" in script_path_lower:
                        video_type = "movie_mashup"
                    elif "çºªå½•ç‰‡" in script_path or "documentary" in script_path_lower:
                        video_type = "documentary"
                
                # ç¬¬äºŒæ­¥ï¼šåŸºäºè§†é¢‘å¸§åˆ†æç»“æœè‡ªåŠ¨è¯†åˆ«æˆ–éªŒè¯ç±»å‹
                if merged_frame_observations and len(merged_frame_observations) > 0:
                    # åˆ†ææ‰€æœ‰å¸§çš„è§‚å¯Ÿç»“æœï¼Œè¯†åˆ«è§†é¢‘å†…å®¹ç±»å‹
                    sample_observations = []
                    for obs in merged_frame_observations[:20]:  # å¢åŠ æ ·æœ¬é‡åˆ°20ä¸ªå¸§
                        observation_text = obs.get('observation', '').lower()
                        if observation_text:
                            sample_observations.append(observation_text)
                    
                    combined_text = ' '.join(sample_observations)
                    logger.info(f"åˆ†æè§†é¢‘å†…å®¹å…³é”®è¯ï¼ˆå‰500å­—ç¬¦ï¼‰: {combined_text[:500]}...")  # è®°å½•æ›´å¤šå†…å®¹ç”¨äºè°ƒè¯•
                    
                    # æ‰©å±•åŠ¨ç‰©å…³é”®è¯ï¼Œä¼˜å…ˆçº§æœ€é«˜
                    animal_keywords = [
                        'åŠ¨ç‰©', 'ç‹®å­', 'è‰åŸ', 'æ£®æ—', 'çŒ©çŒ©', 'é‡ç”ŸåŠ¨ç‰©', 'æ•é£Ÿ', 'çŒç‰©',
                        'æ¾é¼ ', 'èŠ±æ —é¼ ', 'chipmunk', 'squirrel', 'æ¡çº¹æ¾é¼ ',
                        'çŒª', 'å°çŒª', 'çŒªä»”', 'ä»”çŒª', 'çŒªå´½', 'å®¶çŒª', 'é‡çŒª', 'çŒªåª',
                        'ç‹—', 'å°ç‹—', 'çŒ«', 'å°çŒ«', 'é¸¡', 'é¸­', 'é¹…', 'ç‰›', 'ç¾Š', 'é©¬',
                        'é¸Ÿ', 'é±¼', 'é¸Ÿå…½', 'ç‰²ç•œ', 'å® ç‰©', 'å®¶ç•œ',
                        'è¿›é£Ÿ', 'åƒé£Ÿ', 'å–‚é£Ÿ', 'è§…é£Ÿ', 'æ•é£Ÿ', 'åƒä¸œè¥¿', 'åƒé¥²æ–™',
                        'å¤§è‡ªç„¶', 'ç”Ÿæ€', 'æ£®æ—', 'æ—åœ°', 'æ ‘æ¡©', 'æœ¨æ¡©', 'åšæœ', 'æœ¨æ¡Œ',
                        'å†œåœº', 'å…»æ®–', 'ç•œç‰§', 'é¥²å…»',
                        'é¥²æ–™', 'é£Ÿç›†', 'é£Ÿæ§½', 'çŒªåœˆ', 'é¸¡èˆ', 'ç‰›æ£š', 'é£Ÿæ¡¶'
                    ]
                    
                    food_keywords = ['å¨æˆ¿', 'çƒ¹é¥ª', 'åˆ¶ä½œ', 'é£Ÿæ', 'ç¾é£Ÿ', 'æ–™ç†', 'ç…®', 'ç‚’', 'åˆ‡', 'æ“ä½œå°', 'ç¶å°', 'è°ƒå‘³', 'è°ƒæ–™']
                    
                    movie_keywords = ['ç”µå½±', 'æ¼”å‘˜', 'è§’è‰²', 'å‰§æƒ…', 'å½±ç‰‡', 'æ‹æ‘„', 'é•œå¤´']
                    
                    # ç»Ÿè®¡å„ç±»å‹å…³é”®è¯çš„å‡ºç°æ¬¡æ•°
                    animal_count = sum(1 for keyword in animal_keywords if keyword in combined_text)
                    food_count = sum(1 for keyword in food_keywords if keyword in combined_text)
                    movie_count = sum(1 for keyword in movie_keywords if keyword in combined_text)
                    
                    logger.info(f"å…³é”®è¯ç»Ÿè®¡: åŠ¨ç‰©={animal_count}, ç¾é£Ÿ={food_count}, å½±è§†={movie_count}")
                    
                    # å¦‚æœæ²¡æœ‰ä»æ¨¡æ¿ç¡®å®šç±»å‹ï¼ŒåŸºäºå†…å®¹è‡ªåŠ¨è¯†åˆ«
                    if not video_type:
                        # ä¼˜å…ˆçº§ï¼šåŠ¨ç‰© > ç¾é£Ÿ > å½±è§† > ç”Ÿæ´»
                        if animal_count > 0:
                            video_type = "animal_world"
                            detected_keyword = next((kw for kw in animal_keywords if kw in combined_text), 'åŠ¨ç‰©ç›¸å…³')
                            logger.info(f"âœ… åŸºäºè§†é¢‘å†…å®¹è‡ªåŠ¨è¯†åˆ«ï¼šåŠ¨ç‰©ä¸–ç•Œç±»ï¼ˆæ£€æµ‹åˆ°å…³é”®è¯ï¼š{detected_keyword}ï¼Œå‡ºç°{animal_count}æ¬¡ï¼‰")
                            st.info(f"ğŸ· **å†…å®¹ç±»å‹è¯†åˆ«**ï¼šæ£€æµ‹åˆ°è§†é¢‘åŒ…å«åŠ¨ç‰©å†…å®¹ï¼ˆ{detected_keyword}ï¼‰ï¼Œå·²è‡ªåŠ¨é€‰æ‹©'åŠ¨ç‰©ä¸–ç•Œ'ç±»å‹")
                        elif food_count > 0:
                            video_type = "outdoor_food"
                            logger.info(f"åŸºäºè§†é¢‘å†…å®¹è‡ªåŠ¨è¯†åˆ«ï¼šç¾é£Ÿ/ç”Ÿæ´»ç±»ï¼ˆå…³é”®è¯å‡ºç°{food_count}æ¬¡ï¼‰")
                        elif movie_count > 0:
                            video_type = "movie_commentary"
                            logger.info(f"åŸºäºè§†é¢‘å†…å®¹è‡ªåŠ¨è¯†åˆ«ï¼šå½±è§†è§£è¯´ç±»")
                        elif any(keyword in combined_text for keyword in ['å®¤å†…', 'å®¢å…', 'æ²™å‘', 'ç”µè§†', 'æˆ¿é—´', 'å®¶åº­']):
                            video_type = "documentary"
                            logger.info(f"åŸºäºè§†é¢‘å†…å®¹è‡ªåŠ¨è¯†åˆ«ï¼šç”Ÿæ´»/çºªå½•ç‰‡ç±»")
                    else:
                        # å¦‚æœå·²ä»æ¨¡æ¿ç¡®å®šç±»å‹ï¼ŒéªŒè¯å†…å®¹æ˜¯å¦åŒ¹é…
                        if video_type == "animal_world":
                            if animal_count == 0:
                                logger.warning(f"ç”¨æˆ·é€‰æ‹©äº†åŠ¨ç‰©ä¸–ç•Œæ¨¡æ¿ï¼Œä½†è§†é¢‘å†…å®¹ä¸­æœªæ£€æµ‹åˆ°åŠ¨ç‰©å…³é”®è¯")
                                # ä¸å¼ºåˆ¶æ”¹ç±»å‹ï¼Œå› ä¸ºç”¨æˆ·æ˜ç¡®é€‰æ‹©äº†åŠ¨ç‰©ä¸–ç•Œæ¨¡æ¿
                                # ä½†ç»™å‡ºè­¦å‘Š
                                if food_count > 0 or any(keyword in combined_text for keyword in ['å¨æˆ¿', 'çƒ¹é¥ª', 'åˆ¶ä½œ']):
                                    st.warning(f"âš ï¸ **æ³¨æ„**ï¼šæ‚¨é€‰æ‹©äº†'åŠ¨ç‰©ä¸–ç•Œ'æ¨¡æ¿ï¼Œä½†è§†é¢‘å†…å®¹ä¼¼ä¹åŒ…å«ç¾é£Ÿç›¸å…³å†…å®¹ã€‚\n"
                                             f"å¦‚æœè§†é¢‘å®é™…æ˜¯åŠ¨ç‰©å†…å®¹ï¼Œè¯·å¿½ç•¥æ­¤æç¤ºã€‚\n"
                                             f"å¦‚æœè§†é¢‘å®é™…æ˜¯ç¾é£Ÿå†…å®¹ï¼Œè¯·é€‰æ‹©å¯¹åº”çš„æ¨¡æ¿ã€‚")
                            else:
                                logger.info(f"âœ… ç”¨æˆ·é€‰æ‹©çš„åŠ¨ç‰©ä¸–ç•Œæ¨¡æ¿ä¸è§†é¢‘å†…å®¹åŒ¹é…ï¼ˆæ£€æµ‹åˆ°{animal_count}ä¸ªåŠ¨ç‰©å…³é”®è¯ï¼‰")
                        elif video_type == "outdoor_food" and animal_count > food_count:
                            # å¦‚æœæ£€æµ‹åˆ°æ›´å¤šåŠ¨ç‰©å…³é”®è¯ï¼Œç»™å‡ºè­¦å‘Š
                            logger.warning(f"ç”¨æˆ·é€‰æ‹©äº†ç¾é£Ÿæ¨¡æ¿ï¼Œä½†è§†é¢‘å†…å®¹ä¸­æ£€æµ‹åˆ°æ›´å¤šåŠ¨ç‰©å…³é”®è¯ï¼ˆåŠ¨ç‰©:{animal_count} > ç¾é£Ÿ:{food_count}ï¼‰")
                            st.warning(f"âš ï¸ **å†…å®¹ç±»å‹æç¤º**ï¼šæ‚¨é€‰æ‹©äº†'é‡å¤–ç¾é£Ÿ'æ¨¡æ¿ï¼Œä½†è§†é¢‘å†…å®¹ä¼¼ä¹åŒ…å«æ›´å¤šåŠ¨ç‰©ç›¸å…³å†…å®¹ã€‚\n"
                                     f"å¦‚æœè§†é¢‘å®é™…æ˜¯åŠ¨ç‰©å†…å®¹ï¼Œè¯·é€‰æ‹©'åŠ¨ç‰©ä¸–ç•Œ'æ¨¡æ¿é‡æ–°ç”Ÿæˆã€‚")
                
                # ç¬¬ä¸‰æ­¥ï¼šå¦‚æœæ²¡æœ‰è‡ªåŠ¨è¯†åˆ«æˆåŠŸï¼Œä½¿ç”¨é»˜è®¤ç±»å‹
                if not video_type:
                    logger.info(f"æ— æ³•åŸºäºè§†é¢‘å†…å®¹è‡ªåŠ¨è¯†åˆ«ï¼Œä½¿ç”¨é»˜è®¤çºªå½•ç‰‡ç±»å‹")
                    video_type = "documentary"
                
                logger.info(f"âœ… æœ€ç»ˆç¡®å®šçš„è§†é¢‘ç±»å‹: {video_type}")
                
                # ç”Ÿæˆè§£è¯´æ–‡æ¡ˆ
                logger.info(f"ä½¿ç”¨è§†é¢‘ç±»å‹ '{video_type}' ç”Ÿæˆè§£è¯´æ–‡æ¡ˆ")
                update_progress(85, f"æ­£åœ¨ç”Ÿæˆè§£è¯´æ–‡æ¡ˆï¼ˆè§†é¢‘ç±»å‹ï¼š{video_type}ï¼‰...")
                
                narration = generate_narration(
                    markdown_output,
                    text_api_key,
                    base_url=text_base_url,
                    model=text_model,
                    video_type=video_type
                )
                
                logger.info(f"è§£è¯´æ–‡æ¡ˆç”Ÿæˆå®Œæˆï¼Œç±»å‹ï¼š{video_type}")

                # ä½¿ç”¨å¢å¼ºçš„JSONè§£æå™¨
                from webui.tools.generate_short_summary import parse_and_fix_json
                narration_data = parse_and_fix_json(narration)
                
                # éªŒè¯ç”Ÿæˆçš„è§£è¯´æ˜¯å¦ä¸ç”»é¢åŒ¹é…
                if narration_data and 'items' in narration_data:
                    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨é”™è¯¯æç¤ºæ–‡æ¡ˆ
                    error_keywords = [
                        'è§£è¯´æ–‡æ¡ˆç”Ÿæˆå¤±è´¥',
                        'ç”Ÿæˆå¤±è´¥:',
                        'è§†é¢‘å¸§åˆ†ææœªå®Œæˆ',
                        'APIè°ƒç”¨è¶…æ—¶',
                        'è¯·æ£€æŸ¥ç½‘ç»œ',
                        'é”™è¯¯ä¿¡æ¯:'
                    ]
                    for item in narration_data['items']:
                        narration_text = item.get('narration', '') or ''
                        if any(keyword in narration_text for keyword in error_keywords):
                            logger.error(f"è§£è¯´æ–‡æ¡ˆç”Ÿæˆå¤±è´¥ï¼Œæ£€æµ‹åˆ°é”™è¯¯ä¿¡æ¯: {narration_text}")
                            st.error("âŒ **è§£è¯´æ–‡æ¡ˆç”Ÿæˆå¤±è´¥**ï¼šå¤§æ¨¡å‹è¿”å›äº†é”™è¯¯ä¿¡æ¯ã€‚\n\n"
                                     "è¯·ç¡®è®¤æ–‡æœ¬æ¨¡å‹é…ç½® / ç½‘ç»œçŠ¶æ€ï¼Œç„¶åé‡æ–°ç‚¹å‡» 'AIç”Ÿæˆç”»é¢è§£è¯´è„šæœ¬'ã€‚")
                            st.stop()
                            return

                    mismatch_count = 0
                    mismatch_items = []
                    
                    for item in narration_data['items']:
                        picture = item.get('picture', '').lower()
                        narration = item.get('narration', '').lower()
                        
                        # æ£€æŸ¥ç”»é¢å’Œè§£è¯´çš„ä¸»é¢˜æ˜¯å¦åŒ¹é…
                        # æ‰©å±•æ£€æµ‹èŒƒå›´ï¼šåŠ¨ç‰©ç›¸å…³ã€ç”Ÿæ´»åœºæ™¯ã€å½±è§†å†…å®¹ã€ç¾é£Ÿç­‰
                        animal_keywords_in_picture = ['åŠ¨ç‰©', 'æ¾é¼ ', 'èŠ±æ —é¼ ', 'chipmunk', 'æ¡çº¹æ¾é¼ ', 'çŒª', 'å°çŒª', 'ç‹—', 'çŒ«', 'é¸¡', 'é¸­', 'è¿›é£Ÿ', 'åƒé£Ÿ', 'å–‚é£Ÿ', 'åšæœ', 'æ ‘æ¡©', 'æœ¨æ¡©', 'æ£®æ—', 'é¥²å…»', 'å†œåœº', 'å…»æ®–']
                        animal_keywords_in_narration = ['åŠ¨ç‰©', 'æ¾é¼ ', 'èŠ±æ —é¼ ', 'chipmunk', 'æ¡çº¹æ¾é¼ ', 'çŒª', 'å°çŒª', 'ç‹—', 'çŒ«', 'é¸¡', 'é¸­', 'ç‹®å­', 'è‰åŸ', 'æ£®æ—', 'çŒ©çŒ©', 'é‡ç”ŸåŠ¨ç‰©', 'æ•é£Ÿ', 'çŒç‰©', 'å¤§è‡ªç„¶', 'ç”Ÿæ€']
                        
                        life_keywords = ['å®¤å†…', 'å®¢å…', 'æ²™å‘', 'ç”µè§†', 'æˆ¿é—´', 'å¨æˆ¿', 'äººç‰©', 'ç”·å­', 'å¥³å­', 'äºº', 'æ‹¿æ°´æ¯', 'ååœ¨']
                        movie_keywords = ['ç”µå½±', 'æ¼”å‘˜', 'è§’è‰²', 'å‰§æƒ…', 'å½±ç‰‡', 'æ‹æ‘„']
                        food_keywords = ['çƒ¹é¥ª', 'åˆ¶ä½œ', 'é£Ÿæ', 'ç¾é£Ÿ', 'æ–™ç†', 'ç…®', 'ç‚’']
                        
                        # æ£€æµ‹ç”»é¢ç±»å‹
                        is_picture_animal = any(keyword in picture.lower() for keyword in animal_keywords_in_picture)
                        is_picture_life = any(keyword in picture.lower() for keyword in life_keywords)
                        is_picture_movie = any(keyword in picture.lower() for keyword in movie_keywords)
                        is_picture_food = any(keyword in picture.lower() for keyword in food_keywords)
                        
                        # æ£€æµ‹è§£è¯´ç±»å‹
                        is_narration_animal = any(keyword in narration.lower() for keyword in animal_keywords_in_narration)
                        is_narration_life = any(keyword in narration.lower() for keyword in ['ç”Ÿæ´»', 'å®¤å†…', 'æ²™å‘', 'ç”µè§†'])
                        is_narration_movie = any(keyword in narration.lower() for keyword in movie_keywords)
                        is_narration_food = any(keyword in narration.lower() for keyword in food_keywords)
                        
                        # ä¸åŒ¹é…æƒ…å†µ1ï¼šç”»é¢æ˜¯åŠ¨ç‰©ä½†è§£è¯´ä¸æ˜¯
                        if is_picture_animal and not is_narration_animal:
                            mismatch_count += 1
                            mismatch_items.append({
                                'id': item.get('_id'),
                                'picture': item.get('picture', ''),
                                'narration': item.get('narration', ''),
                                'reason': 'ç”»é¢æ˜¯åŠ¨ç‰©å†…å®¹ï¼Œä½†è§£è¯´ä¸åŒ¹é…'
                            })
                        # ä¸åŒ¹é…æƒ…å†µ2ï¼šç”»é¢æ˜¯ç”Ÿæ´»åœºæ™¯ä½†è§£è¯´æ˜¯åŠ¨ç‰©ä¸–ç•Œ
                        elif is_picture_life and is_narration_animal:
                            mismatch_count += 1
                            mismatch_items.append({
                                'id': item.get('_id'),
                                'picture': item.get('picture', ''),
                                'narration': item.get('narration', ''),
                                'reason': 'ç”»é¢æ˜¯ç”Ÿæ´»åœºæ™¯ï¼Œä½†è§£è¯´æ˜¯åŠ¨ç‰©ä¸–ç•Œ'
                            })
                        # ä¸åŒ¹é…æƒ…å†µ3ï¼šç”»é¢æ˜¯åŠ¨ç‰©ä½†è§£è¯´æ˜¯å…¶ä»–ç±»å‹
                        elif is_picture_animal and (is_narration_life or is_narration_movie or is_narration_food):
                            mismatch_count += 1
                            mismatch_items.append({
                                'id': item.get('_id'),
                                'picture': item.get('picture', ''),
                                'narration': item.get('narration', ''),
                                'reason': 'ç”»é¢æ˜¯åŠ¨ç‰©å†…å®¹ï¼Œä½†è§£è¯´æ˜¯å…¶ä»–ç±»å‹'
                            })
                    
                    if mismatch_count > 0:
                        logger.warning(f"æ£€æµ‹åˆ°{mismatch_count}ä¸ªç‰‡æ®µçš„ç”»é¢ä¸è§£è¯´ä¸åŒ¹é…")
                        st.warning(f"âš ï¸ **å†…å®¹ä¸åŒ¹é…è­¦å‘Š**ï¼š\n\n"
                                 f"æ£€æµ‹åˆ° {mismatch_count} ä¸ªç‰‡æ®µçš„è§£è¯´ä¸ç”»é¢å†…å®¹ä¸åŒ¹é…ï¼\n"
                                 f"ä¾‹å¦‚ï¼šç”»é¢æè¿°çš„æ˜¯ç”Ÿæ´»åœºæ™¯ï¼Œä½†è§£è¯´å´æ˜¯åŠ¨ç‰©ä¸–ç•Œçš„å†…å®¹ã€‚\n\n"
                                 f"**å¯èƒ½åŸå› ï¼š**\n"
                                 f"1. é€‰æ‹©çš„æ¨¡æ¿ç±»å‹ä¸è§†é¢‘å®é™…å†…å®¹ä¸ç¬¦\n"
                                 f"2. LLMç”Ÿæˆäº†ä¸æ¨¡æ¿ç›¸å…³ä½†ä¸ç¬¦åˆå®é™…ç”»é¢çš„å†…å®¹\n\n"
                                 f"**å»ºè®®ï¼š**\n"
                                 f"1. æ£€æŸ¥ç”Ÿæˆçš„è„šæœ¬ï¼Œç¡®ä¿æ¯ä¸ªç‰‡æ®µçš„è§£è¯´éƒ½ä¸å¯¹åº”çš„ç”»é¢åŒ¹é…\n"
                                 f"2. å¦‚æœå‘ç°ä¸åŒ¹é…ï¼Œè¯·é‡æ–°ç”Ÿæˆè„šæœ¬\n"
                                 f"3. å¦‚æœè§†é¢‘å†…å®¹ä¸æ¨¡æ¿ç±»å‹ä¸ç¬¦ï¼Œè¯·é€‰æ‹©å¯¹åº”çš„æ¨¡æ¿ç±»å‹")
                        
                        # æ˜¾ç¤ºå‰3ä¸ªä¸åŒ¹é…çš„ä¾‹å­
                        if mismatch_items:
                            st.error("**ä¸åŒ¹é…ç¤ºä¾‹ï¼š**")
                            for i, mismatch in enumerate(mismatch_items[:3], 1):
                                st.text(f"ç‰‡æ®µ {mismatch['id']}:\n"
                                       f"ç”»é¢: {mismatch['picture'][:50]}...\n"
                                       f"è§£è¯´: {mismatch['narration'][:50]}...")
                    else:
                        logger.info("ç”»é¢ä¸è§£è¯´åŒ¹é…éªŒè¯é€šè¿‡")
                        st.success("âœ… **å†…å®¹åŒ¹é…éªŒè¯é€šè¿‡**ï¼šæ‰€æœ‰ç‰‡æ®µçš„è§£è¯´éƒ½ä¸ç”»é¢å†…å®¹åŒ¹é…")

                if not narration_data or 'items' not in narration_data:
                    logger.error(f"è§£è¯´æ–‡æ¡ˆJSONè§£æå¤±è´¥ï¼ŒåŸå§‹å†…å®¹: {narration[:200]}...")
                    raise Exception("è§£è¯´æ–‡æ¡ˆæ ¼å¼é”™è¯¯ï¼Œæ— æ³•è§£æJSONæˆ–ç¼ºå°‘itemså­—æ®µ")

                narration_dict = narration_data['items']
                
                # å…³é”®ä¿®å¤ï¼šç¡®ä¿pictureå­—æ®µä»è§†é¢‘å¸§åˆ†æç»“æœä¸­æ­£ç¡®æå–
                # å¦‚æœLLMç”Ÿæˆçš„pictureä¸ºç©ºæˆ–æ— æ•ˆï¼Œä»frame_observationsä¸­æå–
                if merged_frame_observations:
                    # åˆ›å»ºæ—¶é—´æˆ³åˆ°è§‚å¯Ÿç»“æœçš„æ˜ å°„
                    observation_map = {}
                    for obs in merged_frame_observations:
                        timestamp = obs.get('timestamp', '')
                        observation = obs.get('observation', '')
                        if timestamp and observation:
                            observation_map[timestamp] = observation
                    
                    # ä¸ºæ¯ä¸ªç‰‡æ®µè¡¥å……æˆ–ä¿®æ­£pictureå­—æ®µ
                    for item in narration_dict:
                        picture_value = item.get('picture', '').strip()
                        timestamp_range = item.get('timestamp', '')
                        
                        # å¦‚æœpictureä¸ºç©ºæˆ–æ— æ•ˆï¼Œå°è¯•ä»frame_observationsä¸­æå–
                        if not picture_value or picture_value in ['$', '', 'ç”»é¢æè¿°ç¤ºä¾‹', 'ç”Ÿæˆå¤±è´¥', 'ç”»é¢æè¿°æœªæä¾›']:
                            # å°è¯•ä»timestampä¸­æå–èµ·å§‹æ—¶é—´
                            if timestamp_range and '-' in timestamp_range:
                                start_timestamp = timestamp_range.split('-')[0]
                                # æŸ¥æ‰¾åŒ¹é…çš„è§‚å¯Ÿç»“æœ
                                matched_observation = None
                                for ts, obs in observation_map.items():
                                    if ts.startswith(start_timestamp.split(',')[0]):  # åŒ¹é…åˆ°ç§’çº§åˆ«
                                        matched_observation = obs
                                        break
                                
                                if matched_observation:
                                    item['picture'] = matched_observation
                                    logger.info(f"ç‰‡æ®µ {item.get('_id')} çš„pictureä»frame_observationsä¸­æå–: {matched_observation[:50]}...")
                                else:
                                    # å¦‚æœæ‰¾ä¸åˆ°åŒ¹é…çš„ï¼Œä½¿ç”¨è¯¥æ‰¹æ¬¡çš„æ‰€æœ‰è§‚å¯Ÿç»“æœ
                                    # æŸ¥æ‰¾æ—¶é—´èŒƒå›´åŒ¹é…çš„æ‰¹æ¬¡
                                    for summary in overall_activity_summaries:
                                        if timestamp_range and summary.get('time_range', '') in timestamp_range:
                                            # ä½¿ç”¨æ€»ç»“ä½œä¸ºpicture
                                            item['picture'] = summary.get('summary', 'ç”»é¢æè¿°æœªæä¾›')
                                            logger.info(f"ç‰‡æ®µ {item.get('_id')} çš„pictureä»summaryä¸­æå–")
                                            break
                                    if not item.get('picture') or item['picture'] == 'ç”»é¢æè¿°æœªæä¾›':
                                        item['picture'] = "ç”»é¢æè¿°æœªæä¾›ï¼Œè¯·æ£€æŸ¥è§†é¢‘å¸§åˆ†æç»“æœ"
                                        logger.warning(f"ç‰‡æ®µ {item.get('_id')} æ— æ³•ä»frame_observationsä¸­æå–picture")
                
                # ä¸º narration_dict ä¸­æ¯ä¸ª item æ–°å¢ä¸€ä¸ª OST: 2 çš„å­—æ®µ, ä»£è¡¨ä¿ç•™åŸå£°å’Œé…éŸ³
                narration_dict = [{**item, "OST": 2} for item in narration_dict]
                logger.info(f"è§£è¯´æ–‡æ¡ˆç”Ÿæˆå®Œæˆï¼Œå…± {len(narration_dict)} ä¸ªç‰‡æ®µ")
                
                # éªŒè¯å¹¶ç¡®ä¿æ¯ä¸ªç‰‡æ®µéƒ½æœ‰å¿…éœ€çš„å­—æ®µ
                for i, item in enumerate(narration_dict):
                    # ç¡®ä¿_idå­˜åœ¨ä¸”æ˜¯æ•´æ•°
                    if '_id' not in item:
                        item['_id'] = i + 1
                    elif not isinstance(item['_id'], int):
                        try:
                            item['_id'] = int(item['_id'])
                        except:
                            item['_id'] = i + 1
                    
                    # ç¡®ä¿timestampæ ¼å¼æ­£ç¡®
                    if 'timestamp' not in item or not item['timestamp']:
                        logger.warning(f"ç‰‡æ®µ {item.get('_id', i+1)} ç¼ºå°‘timestampï¼Œä½¿ç”¨é»˜è®¤å€¼")
                        item['timestamp'] = "00:00:00,000-00:00:05,000"
                    
                    # ç¡®ä¿pictureå­˜åœ¨ä¸”ä¸æ˜¯å ä½ç¬¦
                    if 'picture' not in item or not item['picture'] or item['picture'].strip() in ['$', '', 'ç”»é¢æè¿°ç¤ºä¾‹', 'ç”Ÿæˆå¤±è´¥']:
                        logger.warning(f"ç‰‡æ®µ {item.get('_id', i+1)} çš„pictureå­—æ®µæ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤å€¼")
                        item['picture'] = "ç”»é¢æè¿°æœªæä¾›"
                    
                    # ç¡®ä¿narrationå­˜åœ¨ä¸”ä¸æ˜¯å ä½ç¬¦
                    if 'narration' not in item or not item['narration'] or 'ç”Ÿæˆå¤±è´¥' in item['narration'] or 'è§£è¯´æ–‡æ¡ˆç¤ºä¾‹' in item['narration']:
                        logger.warning(f"ç‰‡æ®µ {item.get('_id', i+1)} çš„narrationå­—æ®µæ— æ•ˆ")
                        if 'narration' not in item or not item['narration']:
                            item['narration'] = "è§£è¯´æ–‡æ¡ˆæœªç”Ÿæˆ"
                    
                    # ç¡®ä¿OSTå­˜åœ¨ä¸”æ˜¯æ•´æ•°
                    if 'OST' not in item:
                        item['OST'] = 2
                    elif not isinstance(item['OST'], int):
                        try:
                            item['OST'] = int(item['OST'])
                        except:
                            item['OST'] = 2
                
                # ç»“æœè½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
                script = json.dumps(narration_dict, ensure_ascii=False, indent=2)
                
                # è‡ªåŠ¨ä¿å­˜è„šæœ¬åˆ°æ–‡ä»¶ï¼ˆå…³é”®ä¿®å¤ï¼šç¡®ä¿è„šæœ¬èƒ½è¢«è§†é¢‘ç”Ÿæˆæµç¨‹ä½¿ç”¨ï¼‰
                script_dir = utils.script_dir()
                os.makedirs(script_dir, exist_ok=True)
                
                # ç”Ÿæˆæ–‡ä»¶åï¼ˆä½¿ç”¨æ—¶é—´æˆ³ï¼‰
                timestamp = datetime.now().strftime("%Y-%m%d-%H%M%S")
                script_filename = f"script_{timestamp}.json"
                script_file_path = os.path.join(script_dir, script_filename)
                
                # ä¿å­˜è„šæœ¬åˆ°æ–‡ä»¶
                try:
                    with open(script_file_path, 'w', encoding='utf-8') as f:
                        json.dump(narration_dict, f, ensure_ascii=False, indent=2)
                    logger.info(f"è„šæœ¬å·²è‡ªåŠ¨ä¿å­˜åˆ°: {script_file_path}")
                    
                    # æ›´æ–°session_stateä¸­çš„è„šæœ¬è·¯å¾„ï¼ˆå…³é”®ï¼šç¡®ä¿è§†é¢‘ç”Ÿæˆæµç¨‹èƒ½æ‰¾åˆ°è„šæœ¬ï¼‰
                    st.session_state['video_clip_json_path'] = script_file_path
                    params.video_clip_json_path = script_file_path
                    logger.info(f"è„šæœ¬è·¯å¾„å·²æ›´æ–°: {script_file_path}")
                except Exception as save_error:
                    logger.error(f"ä¿å­˜è„šæœ¬æ–‡ä»¶å¤±è´¥: {save_error}")
                    st.warning(f"âš ï¸ è„šæœ¬å·²ç”Ÿæˆï¼Œä½†ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {save_error}ã€‚è¯·æ‰‹åŠ¨ä¿å­˜è„šæœ¬ã€‚")

            except Exception as e:
                logger.exception(f"å¤§æ¨¡å‹å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯\n{traceback.format_exc()}")
                raise Exception(f"åˆ†æå¤±è´¥: {str(e)}")

            if script is None:
                st.error("ç”Ÿæˆè„šæœ¬å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
                st.stop()
            logger.info(f"çºªå½•ç‰‡è§£è¯´è„šæœ¬ç”Ÿæˆå®Œæˆ")
            if isinstance(script, list):
                st.session_state['video_clip_json'] = script
            elif isinstance(script, str):
                st.session_state['video_clip_json'] = json.loads(script)
            update_progress(100, "è„šæœ¬ç”Ÿæˆå®Œæˆ")

        time.sleep(0.1)
        progress_bar.progress(100)
        status_text.text("ğŸ‰ è„šæœ¬ç”Ÿæˆå®Œæˆï¼")
        st.success("âœ… è§†é¢‘è„šæœ¬ç”ŸæˆæˆåŠŸï¼")
        # åˆ·æ–°é¡µé¢ä»¥æ˜¾ç¤ºç”Ÿæˆçš„è„šæœ¬
        time.sleep(1)  # ç»™ç”¨æˆ·ä¸€ç‚¹æ—¶é—´çœ‹åˆ°æˆåŠŸæ¶ˆæ¯
        st.rerun()

    except Exception as err:
        st.error(f"âŒ ç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(err)}")
        logger.exception(f"ç”Ÿæˆè„šæœ¬æ—¶å‘ç”Ÿé”™è¯¯\n{traceback.format_exc()}")
    finally:
        time.sleep(2)
        progress_bar.empty()
        status_text.empty()
